{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmNegativeValRows(df):\n",
    "       return df[(df >= 0).all(axis=1)]\n",
    "\n",
    "def fitGaussian(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    cov = np.cov(data, rowvar=False)\n",
    "    print(\"matrix and rank\")\n",
    "    print(cov.shape)\n",
    "    print(np.linalg.matrix_rank(cov))\n",
    "    pdfVals = multivariate_normal.pdf(data,mean=mean,cov=cov)\n",
    "    print(\"PDFVals\")\n",
    "    print(pdfVals)\n",
    "    likelihood = np.prod(pdfVals)\n",
    "    \n",
    "    ###\n",
    "    logData = np.log(data)\n",
    "    logMean = np.mean(logData, axis=0)\n",
    "    logCov = np.cov(logData, rowvar=False)\n",
    "    logPdfVals = multivariate_normal.pdf(logData,mean=logMean,cov=logCov)\n",
    "    print(logPdfVals)\n",
    "    logLikelihood = np.prod(logPdfVals)\n",
    "    return(mean,cov,likelihood,\n",
    "           logMean,logCov,logLikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "def scaleData(Xtrn,Xtst):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xtrn)\n",
    "    XtrnScaled = scaler.transform(Xtrn)\n",
    "    XtstScaled = scaler.transform(Xtst) \n",
    "    return(XtrnScaled,XtstScaled)\n",
    "\n",
    "def minMaxScale(data):\n",
    "    scaler = MinMaxScaler((0.1,1))\n",
    "    scaler.fit(data)\n",
    "    scaled = scaler.transform(data)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData1(df):\n",
    "    timeCols = [col for col in df.columns if col.endswith('ime')]\n",
    "    for col in timeCols:\n",
    "        df = df.ix[df[col] >= 0]\n",
    "        df[col] = np.log(df[col] + 1e-20)\n",
    "    return df\n",
    "def transformData2(df):\n",
    "    timeCols = [col for col in df.columns if col.endswith('ime')]\n",
    "    for col in timeCols:\n",
    "        df = df.ix[df[col] >= 0]\n",
    "        df[col] = np.log(df[col] + 1e-20)\n",
    "    (scaled,_) = scaleData(df,df)\n",
    "    return scaled\n",
    "\n",
    "def transformData3(df):\n",
    "    timeCols = [col for col in df.columns if col.endswith('ime')]\n",
    "    non_timeCols = [col for col in df.columns if not(col.endswith('ime'))]\n",
    "    for col in timeCols:\n",
    "        df = df.ix[df[col] >= 0]\n",
    "        df[col] = np.log(df[col] + 1e-20)\n",
    "    (scaled,_) = scaleData(df[non_timeCols],df[non_timeCols])\n",
    "    return scaled\n",
    "\n",
    "def rmNegativeTimes(df):\n",
    "    timeCols = [col for col in df.columns if col.endswith('ime')]\n",
    "    for col in timeCols:\n",
    "        df = df.ix[df[col] > 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianMixtureGridSearch(params,data):\n",
    "    \"\"\"takes a dictionary containing a grid of parameters, fits to data and returns corresponding \n",
    "    GridSearchCV object\"\"\"\n",
    "    clf = GaussianMixture()\n",
    "    grid_search = GridSearchCV(clf, param_grid=params, cv = 3, \n",
    "                                       verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(data)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614\n",
      "703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luiscosta/miniconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "#filepath to all data\n",
    "filepath = \"../data/SATALL12S_data/SATALL12Sft_and_slv_times_with_vals.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "print(len(df))\n",
    "df_clean = rmNegativeTimes(df)\n",
    "print(len(df_clean))\n",
    "clean_data = np.array(df_clean)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potential transformations\n",
    "data_clean1 = transformData1(df) #log the runtimes, leave everything else as is\n",
    "data_clean2   = transformData2(df) #log the runtimes, then standard scale everything.\n",
    "data_clean3   = transformData3(df) #log the runtimes, then standard scale only non-runtime columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 484 candidates, totalling 1452 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1452 out of 1452 | elapsed:  4.6min finished\n",
      "/Users/luiscosta/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {'n_components' : np.linspace(20,30,11).astype(int),\n",
    "                'covariance_type' : ['full','tied','diag','spherical'],\n",
    "                'reg_covar': np.logspace(-10, 1, 11)\n",
    "                }\n",
    "grid_search = gaussianMixtureGridSearch(params, data_clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = np.array(rmNegativeValRows(df))\n",
    "data_clean = data_pos[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 157), dtype=float64)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-107.17469003868563"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.lower_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=29, n_init=1,\n",
       "                precisions_init=None, random_state=None,\n",
       "                reg_covar=0.005011872336272735, tol=0.001, verbose=0,\n",
       "                verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=23, n_init=1,\n",
       "                 precisions_init=None, random_state=None, reg_covar=0.001,\n",
       "                 tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
       "                 weights_init=None),\n",
       " GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=27, n_init=1,\n",
       "                 precisions_init=None, random_state=None,\n",
       "                 reg_covar=0.005011872336272735, tol=0.001, verbose=0,\n",
       "                 verbose_interval=10, warm_start=False, weights_init=None),\n",
       " GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=25, n_init=1,\n",
       "                 precisions_init=None, random_state=None,\n",
       "                 reg_covar=0.005011872336272735, tol=0.001, verbose=0,\n",
       "                 verbose_interval=10, warm_start=False, weights_init=None)]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_dataGS.cv_results_\n",
    "mean_scores = results['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 156)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-89d3f83cc31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_searchMM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussianMixtureGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminMaxScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-e2ab928681d0>\u001b[0m in \u001b[0;36mminMaxScale\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mminMaxScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[1;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    548\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 550\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 156)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "grid_searchMM = gaussianMixtureGridSearch(params,(np.log(minMaxScale(data_clean))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=28, n_init=1,\n",
       "                precisions_init=None, random_state=None, reg_covar=1e-10,\n",
       "                tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
       "                weights_init=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searchMM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores= mean_scores.reshape(tuple(len(params[key]) for key in params))\n",
    "diag_mean_scores = mean_scores[:,2,:]\n",
    "X, Y, Z = np.zeros((diag_mean_scores.size,1)), np.zeros((diag_mean_scores.size,1)), np.zeros((diag_mean_scores.size,1))\n",
    "counter = 0\n",
    "for comp_idx in range(diag_mean_scores.shape[0]):\n",
    "    for reg_idx in range(diag_mean_scores.shape[1]):\n",
    "        X[counter],Y[counter] = params['n_components'][comp_idx], params['reg_covar'][reg_idx]\n",
    "        Z[counter] = diag_mean_scores[comp_idx,reg_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-100, 0)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib qt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(params['n_components'],params['reg_covar'])\n",
    "ax.plot_surface( X, Y, diag_mean_scores.T)\n",
    "ax.set_xlabel(\"number of components\")\n",
    "ax.set_ylabel(\"Covariance Matrix regularization strength\")\n",
    "ax.set_zlabel(\"score\")\n",
    "ax.set_zlim(-100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"GaussianMixtureList.pickle\",\"wb\")\n",
    "pickle.dump(models, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=23, n_init=1,\n",
       "                 precisions_init=None, random_state=None, reg_covar=0.001,\n",
       "                 tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
       "                 weights_init=None),\n",
       " GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=27, n_init=1,\n",
       "                 precisions_init=None, random_state=None,\n",
       "                 reg_covar=0.005011872336272735, tol=0.001, verbose=0,\n",
       "                 verbose_interval=10, warm_start=False, weights_init=None),\n",
       " GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "                 means_init=None, n_components=25, n_init=1,\n",
       "                 precisions_init=None, random_state=None,\n",
       "                 reg_covar=0.005011872336272735, tol=0.001, verbose=0,\n",
       "                 verbose_interval=10, warm_start=False, weights_init=None)]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"GaussianMixtureSATALL.pickle\",\"wb\")\n",
    "pickle.dump(all_dataGS.best_estimator_, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='tied', init_params='kmeans', max_iter=100,\n",
       "                means_init=None, n_components=27, n_init=1,\n",
       "                precisions_init=None, random_state=None,\n",
       "                reg_covar=0.06309573444801943, tol=0.001, verbose=0,\n",
       "                verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataGS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1580546896575699"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataGS.best_estimator_.lower_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
